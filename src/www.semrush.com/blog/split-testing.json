{
  "url": "https://www.semrush.com/blog/split-testing/",
  "title": "Split Testing: What It Is & How To Do It",
  "content": "Running small tests that compare different parts of your website or marketing can make a big difference to how your business performs.\n\nIn this guide, you’ll learn everything you need to know to get started with split testing, including steps to plan and run tests to get meaningful results. \n\nLet’s get started.\n\nWhat Is Split Testing?\n\nSplit testing (also called A/B testing) is the process of comparing two or more versions of website pages, emails, ads, or other digital marketing content to find out which performs best. \n\nSplit testing is an effective way to learn what connects with your audience to improve their experience and increase conversions (i.e., completing a desired goal, like clicking a button).\n\nHow Split Testing Works\n\nIn a split test, you create two versions of your content (like a webpage, email, ad, or social media post): \n\nVersion A is the original. This is called the “control.” \nVersion B is a modified version of the control. Tweaks might include changes to messaging, images, colors, buttons, or design. This version is called the “variant.” \n\n50% of your test audience sees version A, and 50% of your test audience sees version B. \n\nThe version that produces the best results (leads, demos, purchases, etc.) wins. \n\nSay you’re testing two different versions of a checkout page and more people buy using the variant. This is the page you’d move forward with. \n\nIn this example, SplitSignal details a test SEO experiment involving changing a product page’s breadcrumbs.\n\nThe winning version then becomes the control and the testing process starts again. You design a new version to experiment with ways to make the page even better. \n\nYou can also test more than one variant against the control. This is known as A/B/n testing, or multivariate testing.\n\nSo instead of half the audience seeing the control and the other half seeing the variant, you might show 25% the control, 25% variant one, 25% variant two, and 25% variant three.\n\nHowever, the more tests you run, the more website visitors you’ll need. So this methodology is best reserved for websites with high traffic. \n\nA Quick Note on Split Testing Types\n\nThere are distinct differences between split testing for conversions, known as CRO (conversion rate optimization) testing, and SEO (search engine optimization) split testing. \n\nCRO split tests involve duplicating content, such as two versions of a webpage or email, and changing elements to see which version performs best. \n\nSEOsplit testing involves changing an SEO element on your site or page, then comparing those SEO metrics over time. \n\nWhile CRO aims to increase conversions on a page or element, SEO testing aims to increase organic traffic overall. \n\nDuplicating a page in SEOsplit testing is considered cloaking and violates Google’s webmaster guidelines. \n\nPro tip: Learn more about how SEOsplit testing compares to CRO testing.\n\nWhy Is Split Testing Beneficial?\n\nSplit testing helps you understand why websites or campaigns aren’t as effective as you’d like. And what you can make changes to get better results. \n\nLearning what your customers prefer can result in: \n\nBetter user engagement\nLower bounce rates\nHigher conversion rates\nLow-risk changes\n\nLet’s explore these benefits in more detail.\n\nBetter User Engagement\n\nSplit testing helps you improve your website or content marketing to increase user interaction. Each test informs your strategy for current and future campaigns. \n\nSay you want more people to click on the links in its emails. MailerLite tested two versions of an email—one with a GIF at the beginning and one without: \n\nThe email without the GIF performed best, so this version became the control. Mailer Lite then ran another test, replacing the GIF with an image.\n\nThe email without the image continued to generate more clicks: \n\nThe company found that, for its audience, images can be distracting and slow-loading graphics can result in a poor user experience. \n\nKnowing how this small change affects engagement helps MailerLite create more effective content. \n\nLower Bounce Rates\n\nYour bounce rate is the percentage of people who visit a page but leave without performing a specific action. Like staying for a certain amount of time, clicking a link, or making a purchase. \n\nA high bounce rate can be a sign that your webpages aren’t meeting a visitor’s needs. This might be due to several issues, including:\n\nSlow loading pages\nLow-quality design\nIrrelevant content\n\nSplit testing helps you learn why people are leaving your site, so you can make changes that keep them around for longer. \n\nYou can test components such as headlines, messaging, and image placement to find the best combination that keeps visitors on the page.\n\nFor example, online gallery MedaliaArt set up split tests for its holiday sale. The business experimented with a banner displayed prominently on the homepage vs. a banner displayed more discreetly in the sidebar. \n\nFrom this test, they learned that the more prominent messaging helped reduce bounce rates. Furthermore, with people spending more time on the websites, sales also increased. \n\nHigher Conversion Rates\n\nYour conversion rate is the percentage of visitors who come to your website and perform an action. Like signing up for your email list or buying a product.\n\nGetting people to visit your website requires time, effort, and resources. Split testing lets you make the most of your efforts by improving content to turn more visitors into customers. \n\nFor example, game maker Ubisoft experimented with a streamlined variant of a product page that made the buying process less tedious. \n\nHere’s how the control looked:\n\nAnd here’s the variant:\n\nThe variant reduces the amount of scrolling a visitor needs to do, simplifying the buying process. \n\nWith a more user-friendly design, conversions increased by 12%.\n\nIt’s a great example of asking your life: What changes will make a customer’s life easier?\n\nLow-risk Changes\n\nSplit testing lets you make low-risk tweaks to improve performance without harming current conversions. \n\nFor example, you won’t know how your audience will react to a feature or design elements until you launch it. Perform a split test to understand how your audience will receive the change. \n\nIf the audience doesn’t respond positively to the change, experiment with different ways to communicate it.\n\nGetting better results doesn’t require broad-brush transformations. Small edits can make a big difference. \n\n4 Common Split Testing Mistakes and How to Avoid Them\n\nTo uncover meaningful insights, split tests need to follow certain principles. Most importantly, you need to run the right tests with the right intention.\n\nBefore we cover how to run experiments, it’s important to know how not to run them. Here are four common mistakes and what to do to prevent them from ruining your tests.\n\n1. Running Complex Tests\n\nKeep things simple. Test one element at a time and use results to decide on your next test. \n\nWhy only one? \n\nBecause running multiple tests at the same time can distort results. Let’s take SplitSignal’s story about Drizly.\n\nDrizly’s SEO Manager was spending lots of time doing manual SEO testing. And realized the results were unreliable and unscalable.\n\nWith SplitSignal, Drizly focused their efforts on one SEO element to reflect customers’ search intent for one category of pages—“beer brands.”\n\nBy focusing on one element, Drizly saw reliable results.\n\nAnd from there, Drizly could implement the change to the rest of their pages with confidence.\n\nDon’t rush the process. Start with straightforward tests to get more reliable results. \n\n2. Not Testing with a Hypothesis\n\nBefore you test anything, you need a solid reason for doing so. Testing random ideas can waste time and resources. \n\n“Version B” performing better than “Version A” means nothing if you can’t learn from it. Instead, come up with a hypothesis. \n\nA hypothesis is a statement that focuses on a specific problem and provides a starting point for further investigation. \n\nCreate your hypothesis in three steps: find the problem, propose a solution, create your hypothesis. \n\nStep 1. Find the Problem \n\nLook at your webpage or content from the perspective of your visitors. What’s stopping them from taking an action (e.g., filling out a form or completing a purchase)? \n\nFor example, you might run a survey on your site and learn that users felt there wasn’t enough information about the product to consider moving forward.\n\nWhen you’ve found why you believe visitors aren’t converting, you can propose a solution. \n\nStep 2. Propose the Solution\n\nDecide what test you want to run to fix the problem. For example, if your issue is “there’s not enough information about the product,” you might come up with the following proposals:\n\nCreate a video explainer\nAdd an FAQ section\nAdd a section covering the product benefits\nUse images to detail product features\n\nWhen you have your proposal, you can articulate its impact.\n\nStep 3. Create Your Hypothesis\n\nYour hypothesis is an impact statement that covers what you’ll be testing and how it will make a difference. Create it by combining your proposed solution with your problem. \n\nSay your problem is: “There’s not enough information about the product.”\n\nAnd the proposed solution is: “Add an FAQ section.”\n\nYour hypothesis might be: “By adding an FAQ section, there will be more information about the product and users will be more likely to convert.”\n\n3. Stopping Tests Too Early\n\nEarly test results might confirm your hypothesis. The variant outperforms the control as you expected. \n\nSo, why waste any more time running a test that’s telling you what you already know?\n\nBecause results can have nothing to do with your changes. All kinds of factors impact a test: \n\nTime of day, week, month, or year\nSeasonal trends (more people shopping at Christmas time or fewer people shopping in January or February)\nVisitors from different sources (search engines, email newsletters, or social media)\nChanges in mood or circumstance (tests at the start of the month might be picking up consumers who’ve just been paid)\n\nRun tests until they’ve attained statistical significance, or the probability that your result is not due to random chance. \n\nIn other words, be sure that enough people have seen and clicked on a change to make it the biggest deciding factor. \n\nSemrush’s SplitSignal split testing tool, for example, displays significance as Confidence level.\n\nThe generally accepted industry standard for statistical significance is 95%. If your test achieves this score or higher, it’s a sign that your change likely caused the increase or decrease in clicks. \n\nIf your test score is lower than 95%, the change is not large enough to consider it a conclusive probability. \n\nIn addition to reaching statistical significance, your test needs to meet your predetermined sample size. This is the number of people who need to see your control and variant. \n\nFortunately, there’s an easy way to calculate this number. Open up a sample size calculator like this one by Optimizely: \n\nEnter the conversion rate of the control in the space under “Baseline Conversion Rate”. If you’re unsure of how to calculate your conversion rate, check out our beginner’s guide to CRO.\n\nUnder “Minimum Detectable Effect,” enter the change in conversion rate you want to see. The calculator will then work out the required sample size to use in your tests. \n\nIn this example, the control conversion rate is set to 3%, and the relative change is set to 20%. To achieve statistical significance, the test needs 13,000 visitors per variation, so 26,000 in total.  \n\nIt’s also important to run split tests for full-week cycles. So if you’re running your test for one month and starting on Monday, finish it on a Sunday.\n\nVisitor numbers will fluctuate depending on the day and time, so you’ll want to include each day of the week. \n\n4. Focusing on the Wrong Areas\n\nYou can run tests on almost every page element on your website. But that doesn’t mean you should. By focusing on all elements, you risk getting bogged down by insignificant tests. \n\nLet’s look at the results that Google returns for “TikTok video dimensions”:\n\nThe information we need to make videos the correct size is easily available. We don’t need to run a test to find out. \n\nSpend time testing the parts of your website or content that impact conversions the most. Here are some common components to test.\n\nHeadlines\n\nOn average, only 2 out of 10 people will read past the headline (e.g., page title or email subject line). The right headline makes a big difference in how people engage with your content. \n\nFor example, adding the more persuasive “Guaranteed Lowest Prices” to the end of a page title helped Locomotive Agency earn 11.4% more clicks for its client:\n\nTest different versions of headlines based on: \n\nLength. Test short, snappy headlines vs. longer descriptive headlines. Or direct headlines that get straight to the point vs. indirect headlines that raise curiosity (like “Free Guide: SEO Simplified” vs. “Want to Win With Search?”). \nLanguage. Test power adjectives to convey emotion (like “free,” “best,” “killer,” “ultimate,” “essential”), headlines with and without numbers, and odd vs. even numbers. \nCapitalization. Test title case vs. sentence case (e.g. “7 Reasons Change Can Fail” vs. “7 reasons change can fail”). Title case can add authority and help headlines stand out from the body text to grab attention. \n\nTo get started, learn how to write headlines that increase website traffic. \n\nCalls to Action\n\nA call to action What (CTA) encourages your audience to take deliberate action. \n\nFor example, the headline on this Semrush landing page explains the value of the product. The call-to-action button encourages visitors to act on it: “Start your free trial.”\n\nThe design, placement, and wording of buttons or links that ask people to take action can determine how many clicks they get. A small change can boost conversions. \n\nFor example, optimizing emails with a clear CTA at the end rather than the start helped Process Street’s Benjamin Brandall increase open rates and click-through rates. \n\nExperiment with different elements of CTAs:\n\nButton color. Test colors that contrast with other colors on your website to see which grab attention and get clicks.\nText. Change the wording of CTAs to see if they become more persuasive (e.g. “Get Started” vs. “Start Your Free Trial”).\nSize. Test small, medium, and large buttons. Does size impact how many clicks a CTA gets?\nPosition. Try placing CTAs at the top of the page vs. further down the page. Or moving them closer to headlines or benefit copy. \nShape. Test round button corners vs. square button corners. Does the change help draw attention to the CTA?\nLinks vs. buttons. Test CTAs as plain links vs. buttons with colored backgrounds. If your page already has several buttons, a muted tone for less important CTAs might have a positive effect.\n\nRead our guide to CTAs for further information.\n\nVisuals\n\nPeople like to see what they are buying. Images and videos make your product come alive.\n\nFor example, SplitSignal details a case study where they tested a landing page against a variation that included testimonials and images. Brookdale Living saw conversions increase 3.92% with this change.\n\nTo find out what works best, test:\n\nText-only content vs. posts with images or videos\nRegular images vs. animated GIFs or videos\nProduct photos vs. graphics\nTeam images vs. stock photography\nVideo length\nProduct Descriptions \n\nHow you describe your product helps communicate benefits. Descriptions need to tell visitors:\n\nWhat problems your product solves\nHow it helps them \nWhat makes it the best choice \n\nExperiment with: \n\nFormats. Move descriptions up or down the page. Use bullet points to draw attention to important benefits and features. Test bullet points vs. icons that display benefits.\nVisuals. Test images showing products in use (e.g., on a model) vs. on a plain background. Test videos vs. zoomable photos.\nReviews. Do star ratings improve results? Test ratings vs. single customer testimonials.\n\nThese small changes don’t drastically change a page, but the results can be telling. \n\nFor example, adding a review star rating to ecommerce product pages helped CRO agency Growth Rockincrease conversions by 15% and revenue by 17%. \n\nHow to Prepare and Plan Your Next Split Test\n\nSplit testing is a four-stage process: \n\nDetermine what to improve\nHypothesize your test\nCreate variation and run the experiment\nMeasure results\n\nLet’s look at each stage in detail.\n\n1. Determine What to Improve \n\nBefore you start a split test, you need to know what to test. Testing different headlines, for example, won’t improve performance if the design is what’s bothering visitors. \n\nTo find out where to focus your attention, conduct research on how your website is performing.\n\nYou can do so with Google Analytics. In this case, we’ll use GA4.\n\nTo see your top pages, head to “Reports” > “Lifecycle” > “Engagement” > “Pages and screens.”\n\nYou’ll see pages with the most number of views, average engagement time, and conversions.\n\nTo see where your traffic is coming from, head to “Reports” > “Lifecycle” > “Acquisition” > “Traffic acquisition.”\n\nYou’ll see a table sorting your traffic by channel group (e.g., Direct, Organic Search, Display, etc.). But you can also see traffic by “Session source / medium” to see what URLs funneled traffic to your site.\n\nYou can supplement your analysis with additional data from customer interviews and heatmaps.\n\nA heat map is a tool that tracks the motions of a mouse so you can see how people use your website. Some popular options are Hotjar and SessionCam. \n\nBy logging mouse movements, you can see what attracts visitors’ eyes and whether they click what you want them to click. \n\nLearn more about heat map options and how the technology benefits your business.\n\n2. Hypothesize Your Test\n\nYour data will likely give you many different start points. To work out where to start, prioritize ideas using an impact matrix:\n\nFill out this matrix to determine where each potential test falls:\n\nQuick wins: High impact and low effort\nBig bets: High impact and high effort\nFill-ins: Low impact and low effort\nThankless tasks: High impact and low effort \n\nBased on this data and your available resources, choose what you want to test first.\n\nThen hypothesize your test using the three-step framework we outlined earlier: find the problem, propose the solution, create the hypothesis. \n\n3. Create the Variation\n\nTo set up your split test, choose a split testing tool or service. Here are four to try:\n\nSplitSignal. Semrush’s own split testing tool is the best option for running SEO-specific tests. You will need to have at least 100K visitors a month for a significant test, making SplitSignal a better option as your business grows. \nGoogle Optimize. Free to use and beginner friendly. Lets you create and run simple A/B tests, split URL tests, and multivariate tests. \nVWO. Features a WYSIWYG (what-you-see-is-what-you-get) editor for beginners. Plans also come with heat maps and site surveys to help you plan and measure the effectiveness of changes.\nOptimizely. Makes it easy to run small tests without technical expertise. Its Stats Engine also makes analyzing results simple. It is, however, more expensive than Google Optimize or VWO.\n4. Measure Split Test Results\n\nSplit testing tools will show you the results of your test, including the winner, confidence level, and uplift (the difference between performance of a variation and the control group).\n\nBut they won’t analyze results for you. This is something you’ll need to do yourself.\n\nStatistical significance is the biggest sign that your test has had a positive impact. But don’t stop your analysis there. \n\nLook at the audience breakdown of groups that are meaningful to your business (e.g. new visitors, returning visitors, social media visitors). \n\nThis will help you answer questions like:\n\nHow did traffic from different sources perform (like search engines or social media platforms)?\nWhich option worked best with new users?\nWhich option won on mobile or desktop?\n\nWhy is this important? Because even if your test isn’t a huge success, there’s a chance your hypothesis is right with certain audience segments. \n\nEven if the overall result doesn’t go the way you expected, now you’ll know what to avoid. Running a deeper analysis on why it happened will give you even more insights to use in future tests. \n\nGet Started with Split Testing\n\nSplit testing is a learning process and every test is a chance to understand something about your audience, what works, and why.\n\nNever stop testing. Every new test you run should be based on research and a good hypothesis. The more you can test, the more insights you’ll have to improve your marketing.\n\nMost successful split tests will give marginal gains, like 1%, 3%, or 5%. But don’t see these low numbers as a failure; any uplift is positive. \n\nLook at results from a 12-month perspective. If testing helps you increase your conversion rate by 3% each month, your sales will triple over a year. \n\nFocus on small gains. They all add up. \n\nFind Out What to Test Next\n\nwith Semrush SEO Testing Tool\n\nRequest for Free →",
  "headers": {
    "h1": "Split Testing: What It Is & How to Do It",
    "h2": [
      "What Is Split Testing?",
      "Why Is Split Testing Beneficial?",
      "4 Common Split Testing Mistakes and How to Avoid Them",
      "How to Prepare and Plan Your Next Split Test",
      "Get Started with Split Testing"
    ]
  },
  "images": [
    {
      "src": "https://static.semrush.com/blog/uploads/media/36/66/3666dfc6f7c01a1aefb83f898e0af67f/split-testing.svg",
      "alt": "Split Testing"
    },
    {
      "src": "https://static.semrush.com/blog/uploads/media/84/9e/849e53a1cdeb5b37016922f79057f433/Blog-Page-Remove-Breadcrumbs.png",
      "alt": "img-semblog"
    },
    {
      "src": "https://static.semrush.com/blog/uploads/media/6c/f9/6cf939f6d8b44985462c978d70316cec/ab-testing-examples-gif-example.jpg",
      "alt": "ab testing emails with gifs"
    },
    {
      "src": "https://static.semrush.com/blog/uploads/media/52/3c/523c3098e24e7ab05b1b68368c5db634/newsletter-ideas-ab-test.jpg",
      "alt": "emails without images performed better"
    },
    {
      "src": "https://static.semrush.com/blog/uploads/media/d0/4b/d04b6085444215709bb0817e1d8a1bcd/MedaliaArt%20splittest.png",
      "alt": "MedaliaArt holiday sale split test"
    },
    {
      "src": "https://static.semrush.com/blog/uploads/media/b4/0d/b40dc1299c50b41f01edb934466e55af/Ubisoft%20split%20test.png",
      "alt": "Ubisoft control page split test"
    },
    {
      "src": "https://static.semrush.com/blog/uploads/media/28/bf/28bf770e25168d52523e376112564484/Ubisoft%20split%20test%20version%20b.png",
      "alt": "Ubisoft variant page split test"
    },
    {
      "src": "https://static.semrush.com/blog/uploads/media/be/a3/bea3abe333921835ecc91a9216a29f38/drizly-test.png",
      "alt": "drizly split test"
    },
    {
      "src": "https://static.semrush.com/blog/uploads/media/b6/7a/b67ab3a4f39b8aa9ee2b9867b4caffbf/Drizly-Results.png",
      "alt": "img-semblog"
    },
    {
      "src": "https://static.semrush.com/blog/uploads/media/06/28/06281f8a5fe58ab5f18b6202569b151b/Semrush%E2%80%99s%20SplitSignal%20split%20testing%20tool.jpg",
      "alt": "Semrush’s SplitSignal split testing tool"
    },
    {
      "src": "https://static.semrush.com/blog/uploads/media/70/bb/70bb5532f8865ec0aae81cd935b4d491/Optimizely%20sample%20size%20calculator.png",
      "alt": "Optimizely sample size calculator"
    },
    {
      "src": "https://static.semrush.com/blog/uploads/media/97/16/9716ebc3163b37852d80362ef3825229/tik-tok-dimensions-example.jpg",
      "alt": "tik tok video dimensions"
    },
    {
      "src": "https://static.semrush.com/blog/uploads/media/0b/82/0b82b5e6e76ab99c1a22ae66cbd48439/Control-Variant1.png",
      "alt": "img-semblog"
    },
    {
      "src": "https://static.semrush.com/blog/uploads/media/b4/76/b4760f5f64a3f3e5f2e447db63986df1/clear%20CTA%20on%20Semrush%20landing%20page.png",
      "alt": "clear CTA on Semrush landing page"
    },
    {
      "src": "https://static.semrush.com/blog/uploads/media/9d/3a/9d3a1ae39461e65e0f871f9b0a0bb8f4/optimize%20emails%20with%20a%20clear%20CTA.png",
      "alt": "optimizing emails with clear CTA"
    },
    {
      "src": "https://static.semrush.com/blog/uploads/media/10/f5/10f5d6d6c499f3f600ce58e6354b911f/multivariate-testing-cluster-test.jpeg",
      "alt": "multivariate testing cluster test"
    },
    {
      "src": "https://static.semrush.com/blog/uploads/media/7a/02/7a02852ab2cfc5d15507d65c4020c806/adding%20a%20review%20star%20rating%20in%20split%20test.png",
      "alt": "adding a review star rating in split test"
    },
    {
      "src": "https://static.semrush.com/blog/uploads/media/46/1a/461a25863a235c4567845b571570c9e4/top-pages-navigation-ga4.jpg",
      "alt": "top pages navigation GA4"
    },
    {
      "src": "https://static.semrush.com/blog/uploads/media/65/a5/65a553d4c1c8d35db793bdda3e916905/pages-and-screens-table-ga4.jpg",
      "alt": "pages and screens taboe GA4"
    },
    {
      "src": "https://static.semrush.com/blog/uploads/media/e6/0c/e60ce2ca7622989c3f546c2fcd73dacf/traffic-acquisition-report-ga4.jpg",
      "alt": "traffic acquisition report ga4"
    },
    {
      "src": "https://static.semrush.com/blog/uploads/media/96/1a/961afc36a05e58ac952f70b100c0217c/traffic-source-ga4.jpg",
      "alt": "traffic source ga4"
    },
    {
      "src": "https://static.semrush.com/blog/uploads/media/30/a5/30a53d361acc911e84b4f1a2931d1d15/The-Impact-Matrix.png",
      "alt": "the impact matrix"
    },
    {
      "src": "https://static.semrush.com/blog/uploads/files/34/fd/34fd69f6f245f98c9f6c2067a7a1c79b/splitsignal-case-study-51.svg",
      "alt": "ADS illustration"
    },
    {
      "src": "https://static.semrush.com/semblog-next-static/banners/trial-gift.png",
      "alt": "Trial Semrush banner"
    },
    {
      "src": "https://data.adxcel-ec2.com/pixel/?ad_log=referer&action=content&pixid=1bc0716b-4a34-4511-bf3a-c999ecddd356",
      "alt": ""
    },
    {
      "src": "https://data.adxcel-ec2.com/pixel/?ad_log=referer&action=content&pixid=1bc0716b-4a34-4511-bf3a-c999ecddd356",
      "alt": ""
    },
    {
      "src": "https://sp.analytics.yahoo.com/sp.pl?a=10000&d=Mon%2C%2021%20Oct%202024%2014%3A15%3A09%20GMT&n=4d&b=Split%20Testing%3A%20What%20It%20Is%20%26%20How%20To%20Do%20It&.yp=10160379&f=https%3A%2F%2Fwww.semrush.com%2Fblog%2Fsplit-testing%2F&enc=UTF-8&us_privacy=1yn-&yv=1.16.5&tagmgr=gtm",
      "alt": "dot image pixel"
    },
    {
      "src": "https://sp.analytics.yahoo.com/sp.pl?a=10000&b=Split%20Testing%3A%20What%20It%20Is%20%26%20How%20To%20Do%20It&.yp=10160379&f=https%3A%2F%2Fwww.semrush.com%2Fblog%2Fsplit-testing%2F&enc=UTF-8&us_privacy=1yn-&yv=1.16.5&tagmgr=gtm",
      "alt": "dot image pixel"
    },
    {
      "src": "https://bat.bing.com/action/0?ti=5128787&tm=gtm002&Ver=2&mid=b9ef9ea5-aba1-4cd9-a343-591efa3695c6&bo=1&sid=d2d473208fb611eface42b40020ac977&vid=d2d4d4108fb611ef94a28799788b2718&vids=0&msclkid=N&uach=pv%3D15.0.0&pi=0&lg=en-US&sw=1920&sh=1080&sc=24&tl=Split%20Testing%3A%20What%20It%20Is%20%26%20How%20To%20Do%20It&p=https%3A%2F%2Fwww.semrush.com%2Fblog%2Fsplit-testing%2F&r=&lt=706&evt=pageLoad&sv=1&cdb=ARoR&rn=304156",
      "alt": ""
    }
  ],
  "publication_date": null
}