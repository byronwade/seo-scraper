{
  "url": "https://moz.com/blog/becoming-better-seo-scientists-whiteboard-friday",
  "slug": "becoming-better-seo-scientists-whiteboard-friday",
  "title": "Becoming Better SEO Scientists - MozMoz logoMenu openMenu closeSearchMoz logo",
  "description": "Marketers often claim to deal with various aspects of science, but often do so without the rigor of the scientific method. In today's Whiteboard Friday, Mark Traphagen shows us all how to be better scientists in our daily work.",
  "content": "Becoming Better SEO Scientists SEO Basics | Whiteboard Friday By: Mark Traphagen July 10, 2015 The author's views are entirely their own (excluding the unlikely event of hypnosis) and may not always reflect the views of Moz. Table of Contents Copied! By: Mark Traphagen July 10, 2015 Becoming Better SEO Scientists SEO Basics | Whiteboard Friday The author's views are entirely their own (excluding the unlikely event of hypnosis) and may not always reflect the views of Moz. Editor's note: Today we're featuring back-to-back episodes of Whiteboard Friday from our friends at Stone Temple Consulting. Make sure to also check out the second episode, \"UX, Content Quality, and SEO\" from Eric Enge. Like many other areas of marketing, SEO incorporates elements of science. It becomes problematic for everyone, though, when theories that haven't been the subject of real scientific rigor are passed off as proven facts. In today's Whiteboard Friday, Stone Temple Consulting's Mark Traphagen is here to teach us a thing or two about the scientific method and how it can be applied to our day-to-day work. For reference, here's a still of this week's whiteboard. Click on it to open a high resolution image in a new tab! Video transcriptionHowdy, Mozzers. Mark Traphagen from Stone Temple Consulting here today to share with you how to become a better SEO scientist. We know that SEO is a science in a lot of ways, and everything I'm going to say today applies not only to SEO, but testing things like your AdWords, how does that work, quality scores. There's a lot of different applications you can make in marketing, but we'll focus on the SEO world because that's where we do a lot of testing. What I want to talk to you about today is how that really is a science and how we need to bring better science in it to get better results. The reason is in astrophysics, things like that we know there's something that they're talking about these days called dark matter, and dark matter is something that we know it's there. It's pretty much accepted that it's there. We can't see it. We can't measure it directly. We don't even know what it is. We can't even imagine what it is yet, and yet we know it's there because we see its effect on things like gravity and mass. Its effects are everywhere. And that's a lot like search engines, isn't it? It's like Google or Bing. We see the effects, but we don't see inside the machine. We don't know exactly what's happening in there. An artist's depiction of how search engines work. So what do we do? We do experiments. We do tests to try to figure that out, to see the effects, and from the effects outside we can make better guesses about what's going on inside and do a better job of giving those search engines what they need to connect us with our customers and prospects. That's the goal in the end. Now, the problem is there's a lot of testing going on out there, a lot of experiments that maybe aren't being run very well. They're not being run according to scientific principles that have been proven over centuries to get the best possible results. Basic data science in 10 stepsSo today I want to give you just very quickly 10 basic things that a real scientist goes through on their way to trying to give you better data. Let's see what we can do with those in our SEO testing in the future. So let's start with number one. You've got to start with a hypothesis. Your hypothesis is the question that you want to solve. You always start with that, a good question in mind, and it's got to be relatively narrow. You've got to narrow it down to something very specific. Something like how does time on page effect rankings, that's pretty narrow. That's very specific. That's a good question. Might be able to test that. But something like how do social signals effect rankings, that's too broad. You've got to narrow it down. Get it down to one simple question. Then you choose a variable that you're going to test. Out of all the things that you could do, that you could play with or you could tweak, you should choose one thing or at least a very few things that you're going to tweak and say, \"When we tweak this, when we change this, when we do this one thing, what happens? Does it change anything out there in the world that we are looking at?\" That's the variable. The next step is to set a sample group. Where are you going to gather the data from? Where is it going to come from? That's the world that you're working in here. Out of all the possible data that's out there, where are you going to gather your data and how much? That's the small circle within the big circle. Now even though it's smaller, you're probably not going to get all the data in the world. You're not going to scrape every search ranking that's possible or visit every URL. You've got to ask yourself, \"Is it large enough that we're at least going to get some validity?\" If I wanted to find out what is the typical person in Seattle and I might walk through just one part of the Moz offices here, I'd get some kind of view. But is that a typical, average person from Seattle? I've been around here at Moz. Probably not. But this was large enough. Also, it should be randomized as much as possible. Again, going back to that example, if I just stayed here within the walls of Moz and do research about Mozzers, I'd learn a lot about what Mozzers do, what Mozzers think, how they behave. But that may or may not be applicable to the larger world outside, so you randomized. We want to control. So we've got our sample group. If possible, it's always good to have another sample group that you don't do anything to. You do not manipulate the variable in that group. Now, why do you have that? You have that so that you can say, to some extent, if we saw a change when we manipulated our variable and we did not see it in the control group, the same thing didn't happen, more likely it's not just part of the natural things that happen in the world or in the search engine. If possible, even better you want to make that what scientists call double blind, which means that even you the experimenter don't know who that control group is out of all the SERPs that you're looking at or whatever it is. As careful as you might be and honest as you might be, you can end up manipulating the results if you know who is who within the test group? It's not going to apply to every test that we do in SEO, but a good thing to have in mind as you work on that. Next, very quickly, duration. How long does it have to be? Is there sufficient time? If you're just testing like if I share a URL to Google +, how quickly does it get indexed in the SERPs, you might only need a day on that because typically it takes less than a day in that case. But if you're looking at seasonality effects, you might need to go over several years to get a good test on that. Let's move to the second group here. The sixth thing keep a clean lab. Now what that means is try as much as possible to keep anything that might be dirtying your results, any kind of variables creeping in that you didn't want to have in the test. Hard to do, especially in what we're testing, but do the best you can to keep out the dirt. Manipulate only one variable. Out of all the things that you could tweak or change choose one thing or a very small set of things. That will give more accuracy to your test. The more variables that you change, the more other effects and inner effects that are going to happen that you may not be accounting for and are going to muddy your results. Make sure you have statistical validity when you go to analyze those results. Now that's beyond the scope of this little talk, but you can read up on that. Or even better, if you are able to, hire somebody or work with somebody who is a trained data scientist or has training in statistics so they can look at your evaluation and say the correlations or whatever you're seeing, \"Does it have a statistical significance?\" Very important. Transparency. As much as possible, share with the world your data set, your full results, your methodology. What did you do? How did you set up the study? That's going to be important to our last step here, which is replication and falsification, one of the most important parts of any scientific process. So what you want to invite is, hey we did this study. We did this test. Here's what we found. Here's how we did it. Here's the data. If other people ask the same question again and run the same kind of test, do they get the same results? Somebody runs it again, do they get the same results? Even better, if you have some people out there who say, \"I don't think you're right about that because I think you missed this, and I'm going to throw this in and see what happens,\" aha they falsify. That might make you feel like you failed, but it's success because in the end what are we after? We're after the truth about what really works. Think about your next test, your next experiment that you do. How can you apply these 10 principles to do better testing, get better results, and have better marketing? Thanks. Video transcription by Speechpad.com Copied! Back to Top",
  "headers": [
    {
      "level": "H4",
      "text": "Discover top competitors’ winning content"
    },
    {
      "level": "H4",
      "text": "What is your Brand Authority?"
    },
    {
      "level": "H4",
      "text": "Unlock flexible pricing & new endpoints"
    },
    {
      "level": "H4",
      "text": "Surface actionable competitive intel"
    },
    {
      "level": "H1",
      "text": "Becoming Better SEO Scientists"
    },
    {
      "level": "H3",
      "text": "Table of Contents"
    },
    {
      "level": "H1",
      "text": "Becoming Better SEO Scientists"
    },
    {
      "level": "H2",
      "text": "Video transcription"
    },
    {
      "level": "H3",
      "text": "Basic data science in 10 steps"
    },
    {
      "level": "H2",
      "text": "With Moz Pro, you have the tools you need to get SEO right — all in one place."
    },
    {
      "level": "H2",
      "text": "Read Next"
    },
    {
      "level": "H3",
      "text": "How to Easily Find Backlink Opportunities With Moz — Next Level"
    },
    {
      "level": "H3",
      "text": "How I Develop Successful Link Building Strategies for My Clients"
    },
    {
      "level": "H3",
      "text": "An Introduction to Google Tag Manager"
    },
    {
      "level": "H2",
      "text": "Comments"
    }
  ],
  "author": "Mark Traphagen\n          \n            Mark Traphagen\n          \n            Mark Traphagen"
}