{
  "url": "https://moz.com/blog/results-of-google-experimentation-only-the-first-anchor-text-counts",
  "slug": "results-of-google-experimentation-only-the-first-anchor-text-counts",
  "title": "Results of Google Experimentation - Only the First Anchor Text Counts - MozMoz logoMenu openMenu closeSearchMoz logo",
  "description": "Before I was inundated with the responsibilities of running a company and managing a few hundred emails a day, I used to spend a lot of time testing theories about how the search engines handled certain elements on a site or page. I'd test the engines to find answers to questions like:\n\n    Does a…",
  "content": "Results of Google Experimentation - Only the First Anchor Text Counts On-page SEO By: Rand Fishkin March 16, 2008 The author's views are entirely their own (excluding the unlikely event of hypnosis) and may not always reflect the views of Moz. Table of Contents Copied! By: Rand Fishkin March 16, 2008 Results of Google Experimentation - Only the First Anchor Text Counts On-page SEO The author's views are entirely their own (excluding the unlikely event of hypnosis) and may not always reflect the views of Moz. Before I was inundated with the responsibilities of running a company and managing a few hundred emails a day, I used to spend a lot of time testing theories about how the search engines handled certain elements on a site or page. I'd test the engines to find answers to questions like: Does a keyword perform better or worse if it's higher up in the code of a page? (better) What's better, bold or strong tags? (used to be strong, now they appear equal) Does a link with exact anchor text for a query perform better than one that has other words in the anchor text? (exact appears to be better) NOTE: My tests on these are more than a year old, so things may have changed. Obviously, to test the answers to questions like these, you need a very tightly controlled environment, and even then, your tests might reveal answers, but not the relative levels of impact. Sure, having a keyword on a page in strong tags is better than not, but by how much? If one link from the crappiest PR1 page gives more of a boost, is it really worthwhile? I've talked about this testing phenomenon in the past in a Sphinn thread, about whether nofollow sculpting has any impact (I've copied the relevant bit below): Step 1: Register a new domain (preferably one with a domain name that has no results in Google - like yorkfabuzapeloh.com or such) Step 2: Link to that domain's homepage from some social media profiles or pages you control (but make sure they're very obscure and hard to find so no one else discovers and links to it - this is pretty easy to do) Step 3: Create 6 pages on the site, the homepage (A) with two links to pages (B) and (C), pages (D) and (E) - both linked to by page (B) - and page (F) linked to from page (C). It's important to make sure that (B) is the first link on the homepage (A) and (C) is the second link. Step 4: Target a nonsense keyword on pages (D) and (F), which are linked to by pages (B) and (C) respectively. Step 5: Wait until Google has indexed all the pages (usually only a couple days if you link to them from a few sources), then run a search for the nonsense keyword you targeted on (D) and (F). Page (F) will rank first, because there's more link juice pointing to it than to (D), as (D) is only getting half the link weight provided by page (B) while (D) is getting all of (C)'s link weight. Step 6: Add a nofollow to the link from page (B) to page (E), which we haven't done anything with until now. Wait until Google respiders, then check the results again. (D) should now be ranking in front of (F), because it's receiving the same link weight as (F) but the original link from the homepage (A) to (B) is higher up on the page, which gives it a tiny bit more weight. We've replicated this experiment as have several others, and certainly any global link weighting system similar to the original PageRank formula would lead you to this conclusion as well. And I used another test we've performed internally at last week's SEMpdx conference, which created a bit of confusion, and is, ultimately, the reason for this blog post. Directly following my keynote, a question was asked in which link placement on a page became relevant. I commented that it was important to note that only the first anchor text to a given target page would be counted by Google (we haven't yet tested Yahoo!/MSN), but there were a great number of audience members who came up to me during the day asking for clarification -- even Rebecca! And thus, even though we usually keep this kind of information internal (Jane's planning to release a PRO guide with lots of these tests later this year), I figured the beans had already been spilled, so it's my responsibility to clean up the mess. Here's what I mean -- let's say that on your website's homepage, you have two links to your blog. The first link is in the top level navigation, and the anchor text is \"blog.\" The second link is in the body of the homepage and reads \"celebrity news blog.\" That second link's anchor text is NOT going to help the blog page rank for \"celebrity news\" because Google doesn't appear to count the anchor text from multiple links to a target from a single URL. Here's a visual example: Hopefully this clears up the misconception I created at the conference and helps get everyone thinking about the value of testing. It can be complex and time consuming (we run our tests on three nonsense domains, verifying that we get the same results every time), but rewarding. Obviously, even armed with just the knowledge from the test described above, there's a lot of extra thought to put into how your website's internal link structure should function (and yes, you can use nofollow on the first link if you want the second link's anchor text to count - let's test this - orgzhetwarhyu... tyynhaurslfhgn). p.s. Two good questions were asked in the comments that deserve addressing in the post. First, this would appear to apply to the position in the code, not on the actual visual representation of the page, as Google isn't currently running 30+ billion documents through visual page analysis. Second, as far as PR \"leaks\" go, ideally you'd only want one link from any page to any other, but the original PR formula appears to do this for you, as they don't consider multiple votes for a URL by a single page to provide benefit (each page can only vote for another once). p.p.s. On stuff like this, it's never a good idea to just take my word for it (or anyone else's) - run the tests yourself and see the results you get. Since the engines are evolving all the time, the results might be different in six months or six days. Copied! Back to Top",
  "headers": [
    {
      "level": "H4",
      "text": "Discover top competitors’ winning content"
    },
    {
      "level": "H4",
      "text": "What is your Brand Authority?"
    },
    {
      "level": "H4",
      "text": "Unlock flexible pricing & new endpoints"
    },
    {
      "level": "H4",
      "text": "Surface actionable competitive intel"
    },
    {
      "level": "H1",
      "text": "Results of Google Experimentation - Only the First Anchor Text Counts"
    },
    {
      "level": "H3",
      "text": "Table of Contents"
    },
    {
      "level": "H1",
      "text": "Results of Google Experimentation - Only the First Anchor Text Counts"
    },
    {
      "level": "H2",
      "text": "With Moz Pro, you have the tools you need to get SEO right — all in one place."
    },
    {
      "level": "H2",
      "text": "Read Next"
    },
    {
      "level": "H3",
      "text": "What Is Keyword Intent and How Does It Impact Your Conversion Rate?"
    },
    {
      "level": "H3",
      "text": "How Pipedrive Increased Organic Sign-Ups by 33% with BOFU Content"
    },
    {
      "level": "H3",
      "text": "How to Optimize for Google's Featured Snippets [Updated for 2024]"
    },
    {
      "level": "H2",
      "text": "Comments"
    }
  ],
  "author": "Rand Fishkin\n          \n            Rand Fishkin"
}