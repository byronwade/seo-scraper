{
  "url": "https://ahrefs.com/blog/google-search-console-url-inspection-api/",
  "slug": "google-search-console-url-inspection-api",
  "title": "Google‚Äôs New Search Console URL Inspection API: What It Is & How to Use It",
  "description": "The GSC URL Inspection API bulks check data that GSC has on URLs, helping developers and SEOs debug and optimize pages using Google‚Äôs data.",
  "content": "Chris Haines Chris is an SEO director who has 10 years of experience in SEO, agency side. When not involved in SEO, he enjoys messing around with vintage synthesizers, walks on sandy beaches, and a good cup of tea. Get the week's best marketing content Email Subscription Subscribe Leave this field empty if you're human: Contents Diagnosing technical issues on your website can be one of the most time-consuming but important aspects of running a website.To make things worse, Google only allows you to inspect one URL at a time to diagnose potential issues on your website (this is done within Google Search Console).Luckily, there is now a faster way to test your website: enter the Google Search Console URL Inspection API‚Ä¶What is the Google Search Console URL Inspection API?The Google Search Console URL Inspection API is a way to bulk-check the data that Google Search Console has on URLs. Its purpose is to help developers and SEOs more efficiently debug and optimize their pages using Google‚Äôs own data.Here‚Äôs an example of me using the API to check whether a few URLs are indexed and submitted in my sitemap:What type of data can you get from the Google Search Console URL Inspection API?The Google Search Console URL Inspection API allows you to pull a wide range of data. Below is a list of some of the most discussed features:lastCrawlTimeWith this field, you can understand exactly when Googlebot last crawled your website. This is extremely useful for SEOs and developers to measure the frequency of Google‚Äôs crawling of their sites. Previously, you could only get access to this type of data through log file analysis or spot-checking individual URLs with Google Search Console.robotsTxtStateWith this field, you can understand whether you have any robots.txt rules that will block Googlebot. This is something you can check manually, but being able to test it at scale with Google‚Äôs own data is a fantastic step forward.googleCanonical and userCanonicalIn some situations, Google has been known to select a different canonical from the one that has been specified in the code. In this situation, having the ability to compare both (side by side and at scale) using the API is useful for enabling you to make the appropriate changes.crawledAsThis field allows you to understand which user agent is used for a crawl of your site: Mobile/Desktop. The response codes are below for reference:DESKTOP ‚Äì Desktop user agentMOBILE ‚Äì Mobile user agentpageFetchStateUnderstanding the pageFetchState can help you diagnose server errors, not found 4xxs, soft 404s, redirection errors, pages blocked by robots.txt, and invalid URLs. A list of responses is below for reference.FieldWhat it meansPAGE_FETCH_STATE_UNSPECIFIEDUnknown fetch stateSUCCESSFULSuccessful fetchSOFT_404Soft 404BLOCKED_ROBOTS_TXTBlocked by robots.txtNOT_FOUNDNot found (404)ACCESS_DENIEDBlocked due to unauthorized request (401)SERVER_ERRORServer error (5xx)REDIRECT_ERRORRedirection errorACCESS_FORBIDDENBlocked due to access forbidden (403)BLOCKED_4XXBlocked due to other 4xx issue (not 403, 404)INTERNAL_CRAWL_ERRORInternal errorINVALID_URLInvalid URLindexingStateThe indexing state tells you the current status of indexation for the URLs. Apart from the more obvious Pass and Fail responses, there are other responses:NEUTRAL is equivalent to the ‚ÄúExcluded‚Äù message in Search Console.PARTIAL is equivalent to the ‚ÄúValid with warnings‚Äù message in Search Console.VERDICT_UNSPECIFIED means that Google is unable to come to a conclusion about the URL(s) in question.TIPHaving indexing issues? Read our ‚Äú10 ways to get indexed on Google‚Äù post.coverageState This gives you detail on whether a URL has been submitted in your sitemap and indexed.referringUrlsThis allows you to see where each page is linked from, according to Google.Sitemap This enables you to understand which URLs are included in the sitemap(s).Other uses for the APIYou can also use the API to inspect your AMP site‚Äîif you have one.How to use the Google Search Console URL Inspection API step by stepUsing the Google Search Console URL Inspection API involves making a request to Google. The request parameters you need to define are the URL that you want to inspect and also the URL of the property in Google Search Console.The request body contains data with the following structure:If you are curious to learn more about how to use the API, Google has extensive documentation about this.Below is an example of the type of response you can get from the API:If you‚Äôre not comfortable with code or just want to give it a go straight away, you can use valentin.app‚Äôs free Google Bulk Inspect URLs tool. The tool provides a quick way to query the API without any coding skills!Here‚Äôs how to use it. You can:Go to https://valentin.app/inspect.html, authorize access to your Google account, and select the Search Console property you want to test. Then paste your URLs into the box below. (The data will be processed in your browser and not uploaded to a server or shared with anyone.)Click the ‚ÄúInspect URLs‚Äù button. The data will start to pull from the API.Export the data as a CSV or Excel file by clicking the button.Analyze the data and check for any potential issues.How can you use the Google Search Console URL Inspection API in practice?In theory, the Google Search Console URL Inspection API seems like a great way to understand more about your website. However, you can pull so much data that it‚Äôs difficult to know where to start. So let‚Äôs look at a few examples of use cases.1. Site migration ‚Äì diagnosing any technical issuesSite migrations can cause all kinds of issues. For example, developers can accidentally block Google from crawling your site or certain pages via robots.txt.Luckily, the Google Search Console URL Inspection API makes auditing for these issues a doddle.For example, you can check whether you‚Äôre blocking Googlebot from crawling URLs in bulk by calling robotsTxtState.Here is an example of me using the Google Search Console URL Inspection API (via valentin.app) to call robotsTxtState to see the current status of my URLs.As you can see, these pages are not blocked by robots.txt, and there are no issues here.TIP Site migrations can sometimes lead to unforeseen technical SEO issues. After the migration, we recommend using a tool, such as Ahrefs‚Äô Site Audit, to check your website for over 100 pre-defined SEO issues.2. Understand if Google has respected your declared canonicalsIf you make a change to the canonical tags across your site, you will want to know whether or not Google is respecting them.You may be wondering why Google ignores the canonical that you declared. Google can do this for a number of reasons, for example:Your declared canonical is not https. (Google prefers https for canonicals.)Google has chosen a page that it believes is a better canonical page than your declared canonical.Your declared canonical is a noindex page.Below is an example of me using the Google Search Console URL Inspection API to see whether Google has respected my declared canonicals:As we can see from the above screenshot, there are no issues with these particular pages and Google is respecting the canonicals.TIPTo quickly see if the googleCanonical matches the userCanonical, export the data from the Google Bulk Inspect URLs tool to CSV and use an IF formula in Excel. For example, assuming your googleCanonical data is in Column A and your userCanonical is in Column B, you can use the formula =IF(A2=B2, ‚ÄúSelf referencing‚Äù,‚ÄùNon Self Referencing‚Äù) to check for non-matching canonicals. 3. Understand when Google recrawls after you make changes to your siteWhen you update many pages on your website, you will want to know the impact of your efforts. This can only happen after Google has recrawled your site.With the Google Search Console URL Inspection API, you can see the precise time Google crawled your pages by using lastCrawlTime.If you can‚Äôt get access to the log files for your website, then this is a great alternative to understand how Google crawls your site.Here‚Äôs an example of me checking this:As you can see in the screenshot above, lastCrawlTime shows the date and time my website was crawled. In this example, the most recent crawl by Google is the homepage.Understanding when Google recrawls your website following any changes will allow you to link whether or not the changes you made have any positive or negative impact following Google‚Äôs crawl.FAQsHow to get around the Google Search Console URL Inspection API limits?Although the Google Search Console URL Inspection API is limited to 2,000 queries per day, this query limit is determined by Google Property.This means you can have multiple properties within one website if they are verified separately in Google Search Console, effectively allowing you to bypass the limit of 2,000 queries per day.Google Search Console allows you to have 1,000 properties in your Google Search Console account, so this should be more than enough for most users.Can I use the Google Search Console URL Inspection API on any website?Another potential limiting factor is you can only run the Google Search Console URL Inspection API on a property that you own in Google Search Console. If you don‚Äôt have access to the property, then you cannot audit it using the Google Search Console URL Inspection API.So this means auditing a site that you don‚Äôt have access to can be problematic.How accurate is the data?Accuracy of the data itself has been an issue for Google over the last few years. This API gives you access to that data. So arguably, the Google Search Console URL Inspection API is only as good as the data within it.As we have previously shown in our study of Google Keyword Planner‚Äôs accuracy, data from Google is often not as accurate as people assume it to be.Final thoughtsThe Google Search Console URL Inspection API is a great way for site owners to get bulk data directly from Google on a larger scale than what was previously possible from Google Search Console.Daniel Waisberg and the team behind the Google Search Console URL Inspection API have definitely done a great job of getting this released into the wild.But one of the criticisms of the Google Search Console URL Inspection API from the SEO community is that the query rate limit is too low for larger sites. (It is capped at 2,000 queries per day, per property.)For larger sites, this is not enough. Also, despite the possible workarounds, this number still seems to be on the low side.What‚Äôs your experience of using the Google Search Console URL Inspection API? Got more questions? Ping me on Twitter. üôÇ Get the week's best marketing content Email Subscription Subscribe Leave this field empty if you're human: Article by Chris Haines Chris is an SEO director who has 10 years of experience in SEO, agency side. When not involved in SEO, he enjoys messing around with vintage synthesizers, walks on sandy beaches, and a good cup of tea. Keep Learning URL Parameters: A Complete Guide for SEOs URL parameters or query strings are the part of a URL that typically comes after a question mark (?) and are used to pass data along with the URL. How to Remove URLs From Google Search (5 Methods) Using the wrong method can backfire and lead to pages not being removed, or have a negative effect on SEO. Learn how you can get it right in this post. What Is Semantic Search? How It Impacts SEO Semantic search is an information retrieval process used by modern search engines to return the most relevant search results. 9 Reasons Your Website Isn‚Äôt Showing Up On Google (and How to Fix It) Not seeing your website in Google's search results? Learn why you're not in't showing up on Google and how to fix it. SEOs Are Breaking Pagination After Google Changed Rel=Prev/Next - Here‚Äôs How to Get It Right Google may no longer look at rel=prev/next markup for pagination, but many sites are making pagination mistakes that negatively affect SEO.",
  "headers": [
    {
      "level": "H1",
      "text": "Google‚Äôs New Search Console URL Inspection API: What It Is & How to Use¬†It"
    },
    {
      "level": "H2",
      "text": "What is the Google Search Console URL Inspection API?"
    },
    {
      "level": "H2",
      "text": "What type of data can you get from the Google Search Console URL Inspection API?"
    },
    {
      "level": "H3",
      "text": "lastCrawlTime"
    },
    {
      "level": "H3",
      "text": "robotsTxtState"
    },
    {
      "level": "H3",
      "text": "googleCanonical and userCanonical"
    },
    {
      "level": "H3",
      "text": "crawledAs"
    },
    {
      "level": "H3",
      "text": "pageFetchState"
    },
    {
      "level": "H3",
      "text": "indexingState"
    },
    {
      "level": "H3",
      "text": "coverageState"
    },
    {
      "level": "H3",
      "text": "referringUrls"
    },
    {
      "level": "H3",
      "text": "Sitemap"
    },
    {
      "level": "H3",
      "text": "Other uses for the¬†API"
    },
    {
      "level": "H2",
      "text": "How to use the¬†Google Search Console URL Inspection API step by¬†step"
    },
    {
      "level": "H2",
      "text": "How can you use the Google Search Console URL Inspection API in practice?"
    },
    {
      "level": "H3",
      "text": "1. Site migration ‚Äì diagnosing any technical issues"
    },
    {
      "level": "H3",
      "text": "2. Understand if Google has respected your declared canonicals"
    },
    {
      "level": "H3",
      "text": "3. Understand when Google recrawls after you make changes to your¬†site"
    },
    {
      "level": "H2",
      "text": "FAQs"
    },
    {
      "level": "H3",
      "text": "How to get around the Google Search Console URL Inspection API limits?"
    },
    {
      "level": "H3",
      "text": "Can I use the Google Search Console URL Inspection API¬†on any website?"
    },
    {
      "level": "H3",
      "text": "How accurate is the¬†data?"
    },
    {
      "level": "H2",
      "text": "Final thoughts"
    }
  ],
  "author": "Chris Haines"
}