{
  "url": "https://ahrefs.com/blog/de/meta-robots/",
  "slug": "meta-robots",
  "title": "Robots Meta Tag & X-Robots-Tag: Alles was du wissen musst",
  "description": "Robots-Meta-Direktiven teilen Suchmaschinen mit, wo sie sich auf deiner Webseite aufhalten dÃ¼rfen und wo nicht und wie sie deinen Content crawlen sollten.",
  "content": "Michal PecÃ¡nek Vermarkter und Content-Autor bei Ahrefs. SÃ¼chtig nach SEO, Luftfahrt, Parfums, Sushi und Tacos. Inhalt Suchmaschinen dazu anzuhalten, deine Webseite so zu crawlen und indexieren, wie du es mÃ¶chtest, kann eine herausfordernde Aufgabe sein. WÃ¤hrend die robots.txt den Zugang deiner Inhalte fÃ¼r Crawler regelt, verrÃ¤t sie ihnen nicht, ob sie Inhalte indexieren sollen oder nicht.DafÃ¼r sind Meta-Tags und der Xâ€‘Robots-Tag HTTP-Header zustÃ¤ndig.Lass uns eine Sache von vornherein klarstellen. Du kannst die Indexierung nicht mit der robots.txt kontrollieren. Das ist eine hÃ¤ufige FehleinschÃ¤tzung.Die noindex-Regel in der robots.txt wurde nie offiziell von Google unterstÃ¼tzt. Und im Juli 2019 wurde sie offiziell abgeschafft.In diesem Guide wirst du lernen:Was ein Robots-Meta-Tag istWarum der Robots-Meta-Tag wichtig fÃ¼r SEO istDie Werte und Attribute eines Meta-Robots-TagsWie man den Robots-Meta-Tag einsetztWas ein Xâ€‘Robots-Tag istWie man den Xâ€‘Robots-Tag einsetztWann man den Meta-Robots-Tag vs. Xâ€‘Robots-Tag einsetztWie man Crawlbarkeits- und (De)indexierungsfehler vermeidetWas ist ein Robots-Meta-Tag?Ein Robots-Meta-Tag ist ein HTML-Snippet, das Suchmaschinen mitteilt, wie sie bestimmte Seiten crawlen oder indexieren sollen. Es wird im <head>-Bereich einer Webseite platziert und sieht folgendermaÃŸen aus:<meta name=\"robots\" content=\"noindex\" />Warum ist der Robots-Meta-Tag wichtig fÃ¼r SEO?Der Meta-Robots-Tag wird hÃ¤ufig benutzt, um Seiten davon abzuhalten, in den Suchergebnissen zu erscheinen, obwohl es noch weitere AnwendungsfÃ¤lle gibt (mehr dazu spÃ¤ter).Es gibt viele verschiedene Arten von Inhalten, die du vor der Suchmaschinenindexierung verbergen kÃ¶nnen mÃ¶chtest:Inhaltsarme Seiten mit geringem oder keinem Wert fÃ¼r den Nutzer;Seiten auf einer Testumgebung;Admin- und Dankesseiten;Interne Suchergebnisse;PPC-Landing-Pages;Seiten Ã¼ber kommende Werbeveranstaltungen, Conteste oder ProdukteinfÃ¼hrungen;Doppelte Inhalte (Nutze den Canonical Tag um die beste Version zur Indexierung vorzugeben);Ganz allgemein, je grÃ¶ÃŸer deine Seite ist, desto mehr wirst du damit umgehen mÃ¼ssen, die Crawlbarkeit und Indexierung deiner Seite zu verwalten. Du mÃ¶chtest auÃŸerdem, dass Google und andere Suchmaschinen deine Seiten so effizient wie mÃ¶glich crawlen und indexieren kÃ¶nnen. Das richtige Kombinieren von Direktiven auf Seitenebene mit robots.txt und Sitemaps ist sehr wichtig fÃ¼r SEO.Was sind die Werte und Attribute eines Robots-Meta-Tags?Robots-Meta-Tags bestehen aus zwei Attributen: name und content.Du musst Werte fÃ¼r diese beiden Attribute definieren. Lass uns entdecken, welche das sind.Das name Attribut und User-Agent-WerteDas name-Attribut spezifiziert welche Crawler diesen Instruktionen folgen sollen. Dieser Wert ist auch als (UA) User Agent bekannt, da Crawler mit ihrem User Agent identifiziert werden mÃ¼ssen, um eine Seite anzufragen. Dein UA spiegelt den Browser, den du nutzt, wieder, aber Googles User Agents sind zum Beispiel Googlebot oder Googlebot-image.Der UA-Wert â€œrobotsâ€ spricht alle Crawler an. Du kannst auÃŸerdem so viele Robots-Meta-Tags im <head> einfÃ¼gen, wie du benÃ¶tigst. Wenn du zum Beispiel verhindern mÃ¶chtest, dass deine Bilder in der Google- oder Bingsuche auftauchen, fÃ¼ge folgende Meta-Tags hinzu:<meta name=\"googlebot-image\" content=\"noindex\" /><meta name=\"MSNBot-Media\" content=\"noindex\" />Nebenbei bemerkt. Beide Namen und Content-Attribute sind nicht Case-Sensitive. â€œGooglebot-Imageâ€, msnbot-mediaâ€ und â€œNoindexâ€-Attribute funktionieren ebenfalls fÃ¼r die oberen Beispiele. Das content-Attribut und Crawling/Indexierungs-DirektivenDas â€œcontentâ€-Attribut gibt Anweisungen dazu, wie Informationen auf Seiten gecrawlt und indexiert werden sollen. Wenn kein Robots-Meta-Tag vorhanden ist, interpretieren Crawler es als index und follow. Das gibt ihnen die Erlaubnis, die Seite in den Suchergebnissen anzuzeigen und alle Links auf der Seite zu crawlen (wenn nicht anders mit dem rel=â€nofollowâ€-Tag angegeben).Die folgenden sind die unterstÃ¼tzten Werte fÃ¼r die content-Attribute von Google:allDer Standardwert mit â€œindex, followâ€, es gibt keinen Grund diese Direktive je zu nutzen.<meta name=\"robots\" content=\"all\" />noindexWeist Suchmaschinen an, die Seite nicht zu indexieren. Dies hÃ¤lt sie davon ab, in Suchergebnissen zu erscheinen.<meta name=\"robots\" content=\"noindex\" />nofollowHÃ¤lt Crawler davon ab, alle Links auf der Seite zu crawlen. Bitte denke daran, dass diese URLs immer noch indexierbar sein kÃ¶nnen, besonders wenn Backlinks auf sie zeigen.<meta name=\"robots\" content=\"nofollow\" />noneDie Kombination von noindex, nofollow. Vermeide die Nutzung, da andere Suchmaschinen (wie Bing) das nicht unterstÃ¼tzen.<meta name=\"robots\" content=\"none\" />noarchiveVerhindert, dass Google eine gecachte Kopie der Seite in den SERPs anzeigt.<meta name=\"robots\" content=\"noarchive\" />notranslateVerhindert, dass Google eine Ã¼bersetzte Version der Seite in den SERPs anzeigt.<meta name=\"robots\" content=\"notranslate\" />noimageindexVerhindert, dass Google Bilder, die auf der Seite eingebunden sind, indexiert.<meta name=\"robots\" content=\"noimageindex\" />unavailable_after:Teilt Google mit eine Seite nach einem spezifizierten Datum/Zeit nicht mehr in den Suchergebnissen anzuzeigen. Im Prinzip handelt es sich dabei um eine noindex-Direktive mit einem Timer. Das Datum/Zeit muss im RFC 850 Format hinterlegt sein.<meta name=\"robots\" content=\"unavailable_after: Sunday, 01-Sep-19 12:34:56 GMT\" />nosnippetVerhindert alle Text- und Video-Snippets innerhalb der SERPs. Es verhÃ¤lt sich auÃŸerdem gleichzeitig wie ein noarchive.<meta name=\"robots\" content=\"nosnippet\" />WICHTIGER HINWEISSeit Oktober 2019 bietet Google granularere Optionen an um zu kontrollieren, ob und wie du Snippets in den Suchergebnissen anzeigen lassen mÃ¶chtest. Das gibt es zum Teil wegen der europÃ¤ischen Copyright Richtlinie, welche zuerst von Frankreich in seinem neuen Urheberrechtsgesetz implementiert wurde.Am wichtigsten ist, dass dieses Gesetz bereits alle Webseitenbesitzer betrifft. Wie? Weil Google nicht mehr lÃ¤nger Snippets (Text, Bilder oder Video) deiner Seite in Frankreich anzeigt, auÃŸer du willigst explizit mit den neuen Robots-Tags ein.Wir diskutieren unten wie alle diese neuen Tags funktionieren. Falls dies deinen GeschÃ¤ftsbereich betrifft und du nach einer schnellen LÃ¶sung suchst, fÃ¼ge das folgende HTML-Snippet zu jeder Seite hinzu, um Google mitzuteilen, dass du keine BeschrÃ¤nkungen in deinen Snippets mÃ¶chtest:<meta name=\"robots\" content=â€max-snippet:-1, max-image-preview:large, max-video-preview:-1\" />Denk daran, dass wenn du Yoast SEO benutzt, dann dieses CodestÃ¼ck automatisch auf jeder Seite hinzugefÃ¼gt wird, auÃŸer du hast noindex oder nosnippet-Direktiven vergeben.max-snippet:Legt ein Maximum an Zeichen fest, die Google in seinen Text-Snippets anzeigen kann. Die Nutzung von 0 wird keine Text-Snippets anzeigen, wÃ¤hrend â€‘1 kein Limit bei der Textvorschau deklariert.Der folgende Tag setzt das Limit auf 160 Zeichen (Ã¤hnlich wie die Standard Meta-Description-LÃ¤nge.):<meta name=\"robots\" content=\"max-snippet:160\" />max-image-preview:Teilt Google mit ob es, und wie groÃŸ ein Bild sein kann, das fÃ¼r Image-Snippets genutzt werden kann. Diese Direktive hat drei mÃ¶gliche Werte:none â€” Kein Image-Snippet wird gezeigtstandard â€” Ein Standard-Image kann angezeigt werdenlarge â€” Die grÃ¶ÃŸtmÃ¶glichste Image-Vorschau kann angezeigt werden<meta name=\"robots\" content=\"max-image-preview:large\" />max-video-preview:Legt eine maximale Sekundenanzahl fÃ¼r ein Video-Snippet fest. Wie beim Text-Snippet bedeutet 0 keine Anzeige und â€‘1 setzt keine Limits.Der folgende Tag wÃ¼rde Google erlauben maximal 15 Sekunden zu zeigen:<meta name=\"robots\" content=\"max-video-preview:15\" />Ein kurzer Hinweis zur Nutzung des data-nosnippet HTML-AttributsNeben den neuen Robots-Direktiven, die im Oktober 2019 eingefÃ¼hrt wurden, hat Google auch das data-snippet HTML-Attribut eingefÃ¼hrt. Du kannst diesen Tag benutzen, um Teile des Inhalts zu markieren, sodass diese nicht von Google als Snippet verwendet werden.Dies kann in HTML bei div, span und Section-Elementen eingesetzt werden. Das data-nosnippet gilt als boolesches Attribut, was bedeutet das es ohne einen Wert gÃ¼ltig ist.<p>Dies ist ein Text in einem Abschnitt, der als Snippet angezeigt werden kann<span data-nosnippet>doch dieser Teil nicht</span></p><div data-nosnippet>Dies wird nicht in einem Snippet angezeigt</div><div data-nosnippet=\"true\">Und das hier auch nicht</div>Nutzung dieser DirektivenDie meisten SEOs mÃ¼ssen nicht Ã¼ber die Verwendung von noindex und nofollow-Direktiven hinaus gehen, aber es ist gut zu wissen, dass es auch andere Optionen gibt. Bedenke, dass alle oben genannten Direktiven von Google unterstÃ¼tzt werden.Lass uns den Vergleich mit Bing Ã¼berprÃ¼fen:DirektiveGoogleBingallâœ…âŒnoindexâœ…âœ…nofollowâœ…âœ…noneâœ…âŒnoarchiveâœ…âœ…nosnippetâœ…âœ…max-snippet:âœ…âŒmax-image-preview:âœ…âŒmax-video-preview:âœ…âŒnotranslateâœ…âŒnoimageindexâœ…âŒunavailable_after:âœ…âŒDu kannst mehrere Direktiven benutzen und sie kombinieren. Doch wenn sie in Konflikt miteinander stehen (z.B. â€œnoindex, indexâ€) oder eine ist eine Unteranweisung einer anderen (z.B. â€œnoindex, noarchiveâ€), dann wird Google die restriktivste benutzen. In diesem Fall wÃ¤re das einfach â€œnoindexâ€.Nebenbei bemerkt. Snippet-Direktiven kÃ¶nnen von strukturierten Daten Ã¼berschrieben werden, die es Google erlauben, Informationen innerhalb der Auszeichnungen zu benutzen. Wenn du Google davon abhalten mÃ¶chtest Snippets anzuzeigen, dann passe die Auszeichnungen entsprechend an und stelle sicher, dass du kein Lizenzabkommen mit Google hast.Eine Bemerkung zu anderen DirektivenDu wirst vielleicht auch Direktiven Ã¼ber den Weg laufen, die spezifisch fÃ¼r andere Suchmaschinen sind. Ein Beispiel wÃ¤re â€œnoyacaâ€, das Yandex davon abhÃ¤lt, sein eigenes Verzeichnis zu nutzen, um Suchergebnissnippets zu generieren.Andere kÃ¶nnen einmal nÃ¼tzlich gewesen sein und wurden in der Vergangenheit benutzt, doch sie sind bereits veraltet. Zum Beispiel wurde die â€œnoodpâ€-Direktive benutzt, um Suchmaschinen davon abzuhalten, das Open Directory Project zu nutzen, um Snippets zu generieren.Wie man das Robots-Meta-Tag einsetztNun wo du weiÃŸt, was all diese Direktiven tun und wie sie aussehen, ist es an der Zeit zur tatsÃ¤chlichen Implementierung auf deiner Seite zu kommen.Robots-Meta-Tags gehÃ¶ren in die <head> Sektion einer Seite. Es ist ziemlich einfach, wenn du den Code mit HTML-Editoren wie Notepad++ oder Brackets bearbeitest. Aber was, wenn du ein CMS mit SEO-Plugins benutzt?Lass uns auf die beliebtesten da drauÃŸen fokussieren.Implementierung der Robots-Meta-Tags in WordPress unter Verwendung von Yoast SEOGehe zur â€œAdvancedâ€-Sektion unter dem Bearbeitungsblock jedes Artikels oder Seite. Setze den Robots-Meta-Tag nach deinen BedÃ¼rfnissen. Die folgenden Einstellungen wÃ¼rden â€œnoindex, nofollowâ€-Direktiven implementieren.Die â€œMeta robots advancedâ€ Zeile gibt dir die Option, andere Direktiven als â€œnoindexâ€ und â€œnofollowâ€ zu implementieren, so wie noimageindex.Du kannst diese Direktiven auÃŸerdem auch seitenweit nutzen. Gehe zu â€œSearch Appearanceâ€ im Yoast MenÃ¼. Dort kannst du Meta-Robots-Tags auf allen Artikeln, Seiten oder nur bestimmten Taxonomien oder Archiven anpassen.Nebenbei bemerkt. Yoast ist nicht der einzige Weg, wie man Meta-Robots-Tags in WordPress steuern kann. Es gibt eine Menge anderer WordPress-SEO-Plugins mit Ã¤hnlichen Funktionen. Was ist ein Xâ€‘Robots-Tag?Der Robots-Meta-Tag ist geeignet, um hier und da noindex-Direktiven auf HTML-Seiten zu implementieren. Doch was ist, wenn du Suchmaschinen davon abhalten mÃ¶chtest, Dateien so wie Bilder oder PDFs zu indexieren? Genau hier kommen Xâ€‘Robots-Tags ins Spiel.Der Xâ€‘Robots-Tag ist ein HTTP-Header, der von einem Webserver gesendet wird. Anders als beim Meta-Robots-Tag wird er nicht im HTML der Seite platziert. FolgendermaÃŸen kann er aussehen:Das PrÃ¼fen von HTTP-Headern ist etwas komplizierter. Du kannst es auf die alte Weise mit den Developer Tools erledigen oder eine Browser Extension wie Live HTTP Headers benutzen.Die Live-HTTP-Headers-Extension Ã¼berwacht den gesamten HTTP(S)-Traffic, den dein Browser sendet (Request Headers) und empfÃ¤ngt (Response Headers). Es wird live gemessen, also stelle sicher, dass das Plugin aktiviert ist. Gehe dann zur Seite oder Datei, die du untersuchen mÃ¶chtest und Ã¼berprÃ¼fe das Plugin fÃ¼r die Logs. Es sieht wie folgt aus:Wie man den Xâ€‘Robots-Tag einsetztDie Konfiguration hÃ¤ngt vom Typ des Webservers, den du benutzt und welchen Seiten oder Dateien du aus dem Index fernhalten mÃ¶chtest, ab.Die Code-Zeile sieht folgendermaÃŸen aus:Header set X-Robots-Tag â€œnoindexâ€Dieses Beispiel setzt den meist verbreiteten Servertyp vorausâ€”Apache. Der praktischste Weg um HTTP-Header hinzuzufÃ¼gen, ist die Hauptkonfigurationsdatei zu bearbeiten (Ã¼blicherweise httpd.conf) oder .htaccess-Dateien. Das kommt dir bekannt vor? Das ist auch der Ort, an dem Weiterleitungen stattfinden.Du benutzt die selben Werte und Direktiven fÃ¼r den Xâ€‘Robots-Tag wie beim Meta-Robots-Tag. Es sollte aber gesagt sein, dass diese Art der Implementierung etwas fÃ¼r Fortgeschrittene ist. Backups sind dein Freund, denn selbst ein kleiner Syntax-Fehler kann die gesamte Webseite zerstÃ¶ren.PRO TIPPWenn du ein CDN benutzt, dass serverlose Applikationen fÃ¼r Edge-SEO unterstÃ¼tzt, dann kannst du sowohl Robots-Meta-Tags als auch Xâ€‘Robots-Tags auf dem Edge-Server anpassen ohne Ã„nderungen in der darunterliegenden Codebase machen zu mÃ¼ssen.WÃ¤hrend das HinzufÃ¼gen von HTML-Snippets wie die einfachste und geradlinige Option aussieht, kann das manchmal zu kurz gegriffen sein.Nicht-HTML-DateienDu kannst kein HTML-Snippet in Nicht-HTML-Dateien wie PDFs oder Bildern platzieren. Xâ€‘Robots-Tags sind der einzige Weg.Das folgende Snippet (auf einem Apache-Server) wÃ¼rde noindex HTTP-Header fÃ¼r alle PDF-Dateien auf der Seite konfigurieren.<Files ~ \".pdf$\"> Header set X-Robots-Tag \"noindex\" </Files>Direktiven groÃŸflÃ¤chig anwendenWenn du eine ganze (Sub)domain, Unterverzeichnis, Seiten mit bestimmten Parametern oder irgendetwas anderes, das eine Massenbearbeitung erfordert, deindexieren musst, nutze Xâ€‘Robots-Tags. Es ist einfacher.HTTP-Header-Modifizierungen kÃ¶nnen mit regulÃ¤ren AusdrÃ¼cken gegen URLs und Dateinamen gematched werden. Komplizierte Massenbearbeitungen in HTML mit der Suchen und Ersetzen Funktion wÃ¼rde Ã¼blicherweise mehr Zeit und Rechenzeit erfordern.Traffic von alternativen Suchmaschinen zu GoogleGoogle unterstÃ¼tzt sowohl Meta-Robots-Tags und Xâ€‘Robots-Tags, aber das trifft nicht fÃ¼r alle Suchmaschinen zu.Zum Beispiel Seznam, die tschechische Suchmaschine, unterstÃ¼tzt nur Robots-Meta-Tags. Wenn du steuern mÃ¶chtest, wie diese Suchmaschine deine Seiten crawlt und indexiert, dann wird die Verwendung von Xâ€‘Robots-Tags nicht funktionieren. Du musst HTML-Snippets benutzen.Wie du Crawlbarkeits- und (De)indexierungsfehler vermeiden kannstDu mÃ¶chtest alle wertvollen Seiten zeigen, Probleme mit doppelten Inhalten vermeiden und spezifische Inhalte aus dem Index halten. Wenn du eine groÃŸe Webseite verwaltest, dann ist Crawl-Budget eine weitere Sache, der es Beachtung zu schenken gilt.Lass uns einen Blick auf die hÃ¤ufigsten Fehler werfen, die Menschen hinsichtlich Robots-Direktiven machen.Fehler #1: Noindex-Direktiven zu Seiten, die in der robots.txt gesperrt sind, hinzufÃ¼genVerbiete niemals das Crawling von Seiten, die du versuchst zu deindexieren, Ã¼ber die robots.txt. Das zu tun verhindert, dass Suchmaschinen die Seite erneut crawlen und die noindex-Direktive erkennen.Wenn du glaubst, diesen Fehler gemacht zu haben, dann crawle deine Seite mit Ahrefs Site Audit. Suche nach Seiten mit â€œNoindex-Seite erhÃ¤lt organischen Trafficâ€-Fehlern.Nicht indexierbare Seiten, die organischen Traffic erhalten, sind ein klares Zeichen dafÃ¼r, dass diese noch immer indexiert sind. Wenn du den Noindex-Tag nicht kÃ¼rzlich hinzugefÃ¼gt hast, dann ist das wegen einer Crawl-Blockierung in deiner robots.txt. ÃœberprÃ¼fe auf Probleme und behebe diese, wo nÃ¶tig.Fehler #2: Schlechtes Sitemap-ManagementWenn du versuchst Content zu deindexieren, egal ob mit Meta-Robots-Tag oder Xâ€‘Robots-Tag, dann entferne ihn nicht aus deiner Sitemap bis er erfolgreich deindexiert wurde. Andernfalls wird Google mehr Zeit benÃ¶tigen die Seite erneut zu crawlen.@nishanthstephen generally anything you put in a sitemap will be picked up soonerâ€” Gary â€œé¯¨ç†â€ Illyes (@methode) 13 October 2015Setze, um den Deindexierungsprozess weiter zu beschleunigen, das lastmod-Datum in deiner Sitemap auf das Datum, an dem du den noindex Tag hinzugefÃ¼gt hast. Dies begÃ¼nstigt ein erneutes Crawlen und eine Neubewertung.Another trick you can do is submit a sitemap file with a lastmod date matching when you 404â€™d to encourage recrawl & reprocessing.â€” ğŸŒ John ğŸŒ (@JohnMu) 16 January 2017Nebenbei bemerkt. John spricht hier Ã¼ber 404-Seiten. Wir vermuten, dass dies auch Sinn ergibt bezÃ¼glich anderer Ã„nderungen wie dem HinzufÃ¼gen und Entfernen einer Noindex-Direktive. WICHTIGER HINWEISLasse keine nicht indexierbaren Seiten langfristig in deiner Sitemap. Sobald der Inhalt deindexiert wurde, solltest du ihn aus deiner Sitemap entfernen.Wenn du Sorge hast das alte, erfolgreich deindexierte Inhalte noch immer in deiner Sitemap existieren kÃ¶nnten, dann prÃ¼fe den â€œNoindex Seiten Sitemapâ€ Fehler im Ahrefs Site Audit.Fehler #3: Noindex-Direktiven nicht aus der Produktionsebene entfernenCrawler davon abzuhalten etwas auf einer Staging-Umgebung zu crawlen oder zu indexieren ist ein gutes Vorgehen. Manchmal jedoch gerÃ¤t das in die Produktionsumgebung, wird vergessen und dein organischer Traffic sinkt.Noch schlimmer, der Abfall des organischen Traffics kÃ¶nnte nicht so bemerkbar sein wenn es sich um eine Seitenmigration mit Nutzung von 301-Weiterleitungen handelt. Wenn die neuen URLs die Noindex-Direktive haben oder per robots.txt gesperrt sind, dann wirst du noch immer einige Zeit organischen Traffic von den alten Seiten erhalten. Es kann Google bis zu ein paar Wochen abverlangen diese alten URLs zu deindexieren.Wann immer es solche Ã„nderungen auf deiner Seite gibt, behalte einen Blick auf die â€œNoindex Seiteâ€ Warnungen im Ahrefs Site Audit:Um dabei zu helfen Ã¤hnliche Probleme kÃ¼nftig zu vermeiden, solltest du die Checkliste der Entwickler dahingehend erweitern, Disallow-Regeln aus der robots.txt und Noindex-Direktiven zu entfernen bevor etwas auf die Produktionsumgebung geht.Fehler #4: â€œGeheimeâ€ URLs zur robots.txt hinzufÃ¼gen anstatt sie auf noindex zu setzenEntwickler versuchen hÃ¤ufig, Seiten Ã¼ber anstehende Promotions, Rabatte oder ProdukteinfÃ¼hrungen Ã¼ber ein Aussperren in der robots.txt zu verstecken. Das ist ein schlechtes Vorgehen, weil Menschen die robots.txt weiterhin sehen kÃ¶nnen. Deshalb werden diese Seiten schnell geleaked.Behebe das, indem du â€œgeheimeâ€ Seiten aus der robots.txt heraushÃ¤ltst und sie stattdessen auf noindex setzt.SchlussgedankenDas Crawling und die Indexierung deiner Seite grÃ¼ndlich zu verstehen und zu verwalten sind die Grundpfeiler von SEO. Technisches SEO kann ziemlich kompliziert sein, aber Robots-Meta-Tags sind nichts wovon man Angst haben mÃ¼sste.Ich hoffe, dass du nun darauf vorbereitet bist, das beste Vorgehen fÃ¼r langfristige LÃ¶sungen in groÃŸer Menge umzusetzen.Lass es mich Ã¼ber Twitter oder in den Kommentaren wissen, wenn du irgendwelche Fragen hast.Ãœbersetzt von: Sebastian Simon. Sebastian Simon beschÃ¤ftigt sich seit 2009 mit SEO, aktuell tut er das bei seven-bytes.de und heine.de. Get the week's best marketing content Email Subscription Subscribe Leave this field empty if you're human: Artikel von Michal PecÃ¡nek Vermarkter und Content-Autor bei Ahrefs. SÃ¼chtig nach SEO, Luftfahrt, Parfums, Sushi und Tacos.",
  "headers": [
    {
      "level": "H1",
      "text": "Robots Meta Tag & Xâ€‘Robots-Tag: Alles was du wissen musst"
    },
    {
      "level": "H2",
      "text": "Was ist ein Robots-Meta-Tag?"
    },
    {
      "level": "H2",
      "text": "Warum ist der Robots-Meta-Tag wichtig fÃ¼rÂ SEO?"
    },
    {
      "level": "H2",
      "text": "Was sind die Werte und Attribute eines Robots-Meta-Tags?"
    },
    {
      "level": "H3",
      "text": "Das nameÂ Attribut und User-Agent-Werte"
    },
    {
      "level": "H3",
      "text": "Das content-Attribut und Crawling/Indexierungs-Direktiven"
    },
    {
      "level": "H4",
      "text": "all"
    },
    {
      "level": "H4",
      "text": "noindex"
    },
    {
      "level": "H4",
      "text": "nofollow"
    },
    {
      "level": "H4",
      "text": "none"
    },
    {
      "level": "H4",
      "text": "noarchive"
    },
    {
      "level": "H4",
      "text": "notranslate"
    },
    {
      "level": "H4",
      "text": "noimageindex"
    },
    {
      "level": "H4",
      "text": "unavailable_after:"
    },
    {
      "level": "H4",
      "text": "nosnippet"
    },
    {
      "level": "H4",
      "text": "max-snippet:"
    },
    {
      "level": "H4",
      "text": "max-image-preview:"
    },
    {
      "level": "H4",
      "text": "max-video-preview:"
    },
    {
      "level": "H3",
      "text": "Nutzung dieser Direktiven"
    },
    {
      "level": "H2",
      "text": "Wie man das Robots-Meta-Tag einsetzt"
    },
    {
      "level": "H3",
      "text": "Implementierung der Robots-Meta-Tags in WordPress unter Verwendung von YoastÂ SEO"
    },
    {
      "level": "H2",
      "text": "Was ist ein Xâ€‘Robots-Tag?"
    },
    {
      "level": "H2",
      "text": "Wie man den Xâ€‘Robots-Tag einsetzt"
    },
    {
      "level": "H2",
      "text": ""
    },
    {
      "level": "H3",
      "text": "Nicht-HTML-Dateien"
    },
    {
      "level": "H3",
      "text": "Direktiven groÃŸflÃ¤chig anwenden"
    },
    {
      "level": "H3",
      "text": "Traffic von alternativen Suchmaschinen zu Google"
    },
    {
      "level": "H2",
      "text": "Wie du Crawlbarkeits- und (De)indexierungsfehler vermeiden kannst"
    },
    {
      "level": "H3",
      "text": "Fehler #1: Noindex-Direktiven zu Seiten, die in der robots.txt gesperrt sind, hinzufÃ¼gen"
    },
    {
      "level": "H3",
      "text": "Fehler #2: Schlechtes Sitemap-Management"
    },
    {
      "level": "H3",
      "text": "FehlerÂ #3: Noindex-Direktiven nicht aus der Produktionsebene entfernen"
    },
    {
      "level": "H3",
      "text": "Fehler #4: â€œGeheimeâ€ URLs zur robots.txt hinzufÃ¼gen anstatt sie auf noindex zu setzen"
    },
    {
      "level": "H2",
      "text": "Schlussgedanken"
    }
  ],
  "author": "Michal PecÃ¡nek"
}