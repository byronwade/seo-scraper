{
  "url": "https://ahrefs.com/blog/blocked-robots-test/",
  "slug": "blocked-robots-test",
  "title": "The Story of Blocking 2 High-Ranking Pages With Robots.txt",
  "description": "We made the bold move of blocking two high-ranking Ahrefs articles with robots.txt. Learn the results of what happened afterward.",
  "content": "Patrick Stox Patrick Stox is a Product Advisor, Technical SEO, & Brand Ambassador at Ahrefs. He was the lead author for the SEO chapter of the 2021 Web Almanac and a reviewer for the 2022 SEO chapter. He also co-wrote the SEO Book For Beginners by Ahrefs and was the Technical Review Editor for The Art of SEO 4th Edition. He’s an organizer for several groups including the Raleigh SEO Meetup (the most successful SEO Meetup in the US), the Beer and SEO Meetup, the Raleigh SEO Conference, runs a Technical SEO Slack group, and is a moderator for /r/TechSEO on Reddit. Get the week's best marketing content Email Subscription Subscribe Leave this field empty if you're human: Contents I blocked two of our ranking pages using robots.txt. We lost a position here or there and all of the featured snippets for the pages. I expected a lot more impact, but the world didn’t end.WarningI don’t recommend doing this, and it’s entirely possible that your results may be different from ours.I was trying to see the impact on rankings and traffic that the removal of content would have. My theory was that if we blocked the pages from being crawled, Google would have to rely on the link signals alone to rank the content.However, I don’t think what I saw was actually the impact of removing the content. Maybe it is, but I can’t say that with 100% certainty, as the impact feels too small. I’ll be running another test to confirm this. My new plan is to delete the content from the page and see what happens.My working theory is that Google may still be using the content it used to see on the page to rank it. Google Search Advocate John Mueller has confirmed this behavior in the past.So far, the test has been running for nearly five months. At this point, it doesn’t seem like Google will stop ranking the page. I suspect, after a while, it will likely stop trusting that the content that was on the page is still there, but I haven’t seen evidence of that happening.Keep reading to see the test setup and impact. The main takeaway is that accidentally blocking pages (that Google already ranks) from being crawled using robots.txt probably isn’t going to have much impact on your rankings, and they will likely still show in the search results.ContentsTest setupI chose the same pages as used in the “impact of link” study, except for the article on SEO pricing because Joshua Hardwick had just updated it. I had seen the impact of removing the links to these articles and wanted to test the impact of removing the content. As I said in the intro, I’m not sure that’s actually what happened.I blocked these two pages on January 30, 2023:Top Bing SearchesTop YouTube SearchesThese lines were added to our robots.txt file:Disallow: /blog/top-bing-searches/Disallow: /blog/top-youtube-searches/ResultsAs you can see in the charts below, both pages lost some traffic. But it didn’t result in much change to our traffic estimate like I was expecting.Traffic for the “Top YouTube Searches” article.Traffic for the “Top Bing Searches” article.Looking at the individual keywords, you can see that some keywords lost a position or two and others actually gained ranking positions while the page was blocked from crawling.The most interesting thing I noticed is that they lost all featured snippets. I guess that having the pages blocked from crawling made them ineligible for featured snippets. When I later removed the block, the article on Bing searches quickly regained some snippets.Organic keywords for the “Top Bing Searches” article.Organic keywords for the “Top YouTube Searches” article.The most noticeable impact to the pages is on the SERP. The pages lost their custom titles and displayed a message saying that no information was available instead of the meta description.This was expected. It happens when a page is blocked by robots.txt. Additionally, you’ll see the “Indexed, though blocked by robots.txt” status in Google Search Console if you inspect the URL.I believe that the message on the SERPs hurt the clicks to the pages more than the ranking drops. You can see some drop in the impressions, but a larger drop in the number of clicks for the articles.Traffic for the “Top YouTube Searches” article:Traffic for the “Top Bing Searches” article:Final thoughtsI don’t think any of you will be surprised by my commentary on this. Don’t block pages you want indexed. It hurts. Not as bad as you might think it does—but it still hurts. Get the week's best marketing content Email Subscription Subscribe Leave this field empty if you're human: Article by Patrick Stox Patrick Stox is a Product Advisor, Technical SEO, & Brand Ambassador at Ahrefs. He was the lead author for the SEO chapter of the 2021 Web Almanac and a reviewer for the 2022 SEO chapter. He also co-wrote the SEO Book For Beginners by Ahrefs and was the Technical Review Editor for The Art of SEO 4th Edition. He’s an organizer for several groups including the Raleigh SEO Meetup (the most successful SEO Meetup in the US), the Beer and SEO Meetup, the Raleigh SEO Conference, runs a Technical SEO Slack group, and is a moderator for /r/TechSEO on Reddit. Keep Learning Ranking #1 on Google Is Overrated (Ahrefs’ Study of 100k Keywords) Still trying to rank #1 for your target keywords? We studied ~100k keywords and found that ranking #1 is often overrated. How Many New Backlinks Do Top-ranking Pages Get Over Time [New Data by Ahrefs] Do top-ranking pages get links at a faster pace than lower-ranking pages? We analyzed 200,000 top-ranking web pages across 10,000 keywords to find out. Anchor Text: A Data‐Driven Guide (384,614 Web Pages Studied) What is anchor text? Does it influence search engine rankings? How do you optimize it for SEO? Learn everything you need to know here. Do Links From Pages With Traffic Help You Rank Higher? [Ahrefs Study] Links are important for SEO. But what makes a good link? Should you aim to get links from pages with traffic, or does that not matter so much? 6 Important Insights About Title Tags (953,276 Pages Studied) We analyzed the SERP titles and title tags for 953,276 pages ranking in the top 10 results. Here's what we learned.",
  "headers": [
    {
      "level": "H1",
      "text": "The Story of Blocking 2 High-Ranking Pages With Robots.txt"
    },
    {
      "level": "H2",
      "text": "Test setup"
    },
    {
      "level": "H2",
      "text": "Results"
    },
    {
      "level": "H2",
      "text": "Final thoughts"
    }
  ],
  "author": "Patrick Stox"
}